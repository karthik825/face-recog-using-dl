{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the paths for the parent directory and the train/test directories\n",
    "parent_dir = '/home/karthik/karthik/sem6/facerecog/dataset'\n",
    "train_dir = os.path.join(parent_dir, 'train-cropped')\n",
    "test_dir = os.path.join(parent_dir, 'test-cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Crop and resize the first face found\n",
    "    if len(faces) > 0:\n",
    "        x, y, w, h = faces[0]\n",
    "        image = image[y:y+h, x:x+w]\n",
    "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Convert the image to a numpy array and normalize its values\n",
    "        image = np.array(image, dtype=np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        return image\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'abhiram': 0,\n",
    "    'jagadeeshan': 1,\n",
    "    'jagannath': 2,\n",
    "    'kiran': 3,\n",
    "    'kodam': 4,\n",
    "    'praneeth': 5,\n",
    "    'rahul': 6,\n",
    "    'samarth': 7,\n",
    "    'sumanth': 8,\n",
    "    'vinay': 9\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory, label_map):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label_name in os.listdir(directory):\n",
    "        label = label_map[label_name]\n",
    "        label_dir = os.path.join(directory, label_name)\n",
    "        for image_name in os.listdir(label_dir):\n",
    "            image_path = os.path.join(label_dir, image_name)\n",
    "            image = preprocess_image(image_path)\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "    images = np.stack(images)\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_dataset(train_dir, label_map)\n",
    "test_images, test_labels = load_dataset(test_dir, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(os.listdir(train_dir)), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 4.5248 - accuracy: 0.0777 - val_loss: 2.2697 - val_accuracy: 0.2222\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 7s 2s/step - loss: 2.2814 - accuracy: 0.2136 - val_loss: 2.3231 - val_accuracy: 0.0556\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 7s 2s/step - loss: 2.2308 - accuracy: 0.2330 - val_loss: 2.2770 - val_accuracy: 0.1667\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 7s 2s/step - loss: 2.1469 - accuracy: 0.2427 - val_loss: 2.1555 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 2.0283 - accuracy: 0.4175 - val_loss: 2.0481 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.8043 - accuracy: 0.4854 - val_loss: 1.8045 - val_accuracy: 0.3889\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.4241 - accuracy: 0.5340 - val_loss: 1.5541 - val_accuracy: 0.5556\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.0291 - accuracy: 0.7476 - val_loss: 1.2359 - val_accuracy: 0.4444\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.7445 - accuracy: 0.7573 - val_loss: 1.2329 - val_accuracy: 0.6111\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.7402 - accuracy: 0.7476 - val_loss: 1.0382 - val_accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.0382 - accuracy: 0.5556\n",
      "Test loss: 1.04, Test accuracy: 55.56%\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "Image 1: Actual label - 1, Predicted label - 1\n",
      "Image 2: Actual label - 2, Predicted label - 8\n",
      "Image 3: Actual label - 2, Predicted label - 2\n",
      "Image 4: Actual label - 4, Predicted label - 9\n",
      "Image 5: Actual label - 4, Predicted label - 9\n",
      "Image 6: Actual label - 7, Predicted label - 9\n",
      "Image 7: Actual label - 7, Predicted label - 9\n",
      "Image 8: Actual label - 5, Predicted label - 5\n",
      "Image 9: Actual label - 5, Predicted label - 9\n",
      "Image 10: Actual label - 8, Predicted label - 8\n",
      "Image 11: Actual label - 8, Predicted label - 8\n",
      "Image 12: Actual label - 0, Predicted label - 4\n",
      "Image 13: Actual label - 9, Predicted label - 9\n",
      "Image 14: Actual label - 9, Predicted label - 3\n",
      "Image 15: Actual label - 6, Predicted label - 6\n",
      "Image 16: Actual label - 6, Predicted label - 6\n",
      "Image 17: Actual label - 3, Predicted label - 3\n",
      "Image 18: Actual label - 3, Predicted label - 3\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test loss: {test_loss:.2f}, Test accuracy: {test_accuracy:.2%}')\n",
    "\n",
    "# Predict the labels of the test images\n",
    "predicted_labels = model.predict(test_images)\n",
    "\n",
    "# Print the images and predicted labels for the test data\n",
    "for i in range(len(test_images)):\n",
    "    image = test_images[i]\n",
    "    label = test_labels[i]\n",
    "    predicted_label = np.argmax(predicted_labels[i])\n",
    "    print(f'Image {i+1}: Actual label - {label}, Predicted label - {predicted_label}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
